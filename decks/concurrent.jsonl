{"front": "What are the three main features of concurrent systems discussed in the course?", "back": "1. Reliable vs Unreliable\n2. Synchronous vs Asynchronous\n3. Shared memory vs Channel-based communication\n\nThe course focuses on reliable, asynchronous, and shared memory systems."}
{"front": "What is the definition of a sequential algorithm?", "back": "A sequential algorithm is a formal description of the behavior of an abstract sequential state machine."}
{"front": "What is the difference between a program and a process?", "back": "A program is a sequential algorithm written in a programming language (TEXT), while a process is a program executed on a concrete machine, characterized by its state (the values of the PC and other registers) (ACTION)."}
{"front": "What are the two primary types of interaction in concurrent systems?", "back": "1. Cooperation: Different processes work together to succeed in their task\n2. Competition: Different processes aim at executing some action, but only one (or few) of them succeeds"}
{"front": "What is a Critical Section?", "back": "A Critical Section is a set of code parts that must be run without interferences, i.e., when a process is in a Critical Section (on a certain shared object), then no other process is in a Critical Section (on that shared object)."}
{"front": "What is the MUTEX problem?", "back": "The MUTEX (Mutual Exclusion) problem is to design an entry protocol (lock) and an exit protocol (unlock) such that, when used to encapsulate a Critical Section (for a given shared object), they ensure that at most one process at a time is in a Critical Section (for that shared object)."}
{"front": "What are the two essential properties that every solution to a concurrent problem should satisfy?", "back": "1. Safety: \"Nothing bad ever happens\"\n2. Liveness: \"Something good eventually happens\"\n\nBoth are needed to avoid trivial solutions. Safety is necessary for correctness, liveness for meaningfulness."}
{"front": "What are the three main liveness properties for MUTEX, ordered from weakest to strongest?", "back": "1. Deadlock freedom: If there is at least one invocation of lock, eventually at least one process enters a Critical Section\n2. Starvation freedom: Every invocation of lock eventually grants access to the associated Critical Section\n3. Bounded bypass: There exists a function f such that every lock enters the Critical Section after at most f(n) other Critical Sections"}
{"front": "What is an Atomic Read/Write register?", "back": "An Atomic Read/Write register is a storage unit that can be accessed through two operations (READ and WRITE) such that:\n1. Each operation looks instantaneous on the timeline\n2. Operations don't happen simultaneously\n3. Every READ returns the closest preceding value written in the register, or the initial value"}
{"front": "What are the different types of Atomic Read/Write registers based on read/write access?", "back": "- SRSW: Single-Read/Single-Write\n- SRMW: Single-Read/Multiple-Write\n- MRSW: Multiple-Read/Single-Write\n- MRMW: Multiple-Read/Multiple-Write"}
{"front": "Describe Peterson's algorithm for 2 processes", "back": "```\nInitialize FLAG[0] and FLAG[1] to down\n\nlock(i) :=\n  FLAG[i] ← up\n  AFTER_YOU ← i\n  wait (FLAG[1-i] = down OR AFTER_YOU ≠ i)\n  return\n\nunlock(i) :=\n  FLAG[i] ← down\n  return\n```\n\nFeatures:\n- Satisfies MUTEX\n- Satisfies bounded bypass with bound = 1\n- Requires 2 one-bit SRSW registers (flags) and 1 one-bit MRMW register (AFTER_YOU)\n- Each lock-unlock requires 5 accesses to registers"}
{"front": "How does Peterson's algorithm ensure MUTEX for 2 processes?", "back": "Proof by contradiction: Assume both p0 and p1 are simultaneously in CS.\n\nFor p0 to enter its CS, either:\n- FLAG[1] = down: only possible if p1 hasn't raised its flag yet, which means p1 cannot be in CS\n- AFTER_YOU = 1: only possible if p1 wrote AFTER_YOU after p0, but then p1 cannot be in CS\n\nEither case leads to a contradiction, proving MUTEX."}
{"front": "How does Peterson's algorithm ensure bounded bypass with bound 1?", "back": "If p0 invokes lock:\n- If the wait condition is true, it wins immediately (wait = 0)\n- Otherwise, FLAG[1]=up AND AFTER_YOU=0. This means p1 has invoked lock and will eventually enter CS and unlock\n- If p1 never locks again, p0 will eventually read FLAG[1]=down and win (wait = 1)\n- If p1 locks again, either p0 reads FLAG[1] before p1 locks and wins (wait = 1), or p1 sets AFTER_YOU=1 and suspends in its wait, allowing p0 to win (wait = 1)"}
{"front": "Describe Peterson's algorithm for n processes", "back": "```\nInitialize FLAG[i] to 0, for all i\n\nlock(i) :=\n  for lev = 1 to n-1 do\n    FLAG[i] ← lev\n    AFTER_YOU[lev] ← i\n    wait (∀k≠i. FLAG[k] < lev OR AFTER_YOU[lev] ≠ i)\n  return\n\nunlock(i) :=\n  FLAG[i] ← 0\n  return\n```\n\nIt satisfies MUTEX and starvation freedom, but not bounded bypass.\nCosts: n MRSW registers of ⌈log₂ n⌉ bits (FLAG), n-1 MRMW registers of ⌈log₂ n⌉ bits (AFTER_YOU), and (n-1)(n+2) accesses for locking and 1 access for unlocking."}
{"front": "What is the key lemma for proving MUTEX in n-process Peterson's algorithm?", "back": "Lemma: For every ℓ ∈ {0,…,n-1}, at most n-ℓ processes are at level ℓ.\n\nWhen ℓ = n-1, this implies that at most 1 process can be at level n-1 (i.e., in the Critical Section), which proves MUTEX."}
{"front": "Why doesn't n-process Peterson's algorithm satisfy bounded bypass?", "back": "Consider 3 processes, with one \"sleeping\" in its first wait, while the other two alternate entering the CS. When the sleeping process wakes up, it can eventually pass to level 2 and win, but the sleep can be arbitrarily long. During this time, the other two processes may have entered an unbounded number of CSs."}
{"front": "What is the Tournament-based algorithm for MUTEX and what is its complexity?", "back": "The Tournament-based algorithm uses a tournament of MUTEX between pairs of processes, applying Peterson's algorithm for 2 processes. A process wins after ⌈log₂ n⌉ competitions, each of constant cost.\n\nThis reduces the complexity from O(n²) of the regular Peterson's algorithm to O(log n)."}
{"front": "Describe Lamport's Fast MUTEX algorithm", "back": "```\nInitialize Y at ⊥, X at any value (e.g., 0), all FLAG[i] at down\n\nlock(i) :=\n  * FLAG[i] ← up\n    X ← i\n    if Y ≠ ⊥ then \n      FLAG[i] ← down\n      wait Y = ⊥\n      goto *\n    else Y ← i\n      if X = i then return\n      else FLAG[i] ← down\n           ∀j.wait FLAG[j] = down\n           if Y = i then return\n           else wait Y = ⊥\n                goto *\n\nunlock(i) := \n  Y ← ⊥\n  FLAG[i] ← down\n  return\n```\n\nWithout contention, this requires 5 accesses to the shared registers. It satisfies MUTEX and deadlock freedom (but not starvation freedom)."}
{"front": "How does Lamport's Fast MUTEX algorithm ensure MUTEX?", "back": "Proof by examining how pi can enter CS:\n\nCase 1: pi enters via direct path (F[i]←up, X←i, Y=⊥, Y←i, X=i)\n- For pj to enter, it must find Y=⊥, which can only happen after pi unlocks\n- pj must have written X after pi, so when pj reads X, it finds X≠j and must wait for pi's unlock\n\nCase 2: pi enters through the longer path involving the wait for all flags down\n- Similar reasoning shows that any pj must either finish its CS before pi starts, or be blocked until pi unlocks"}
{"front": "What is the Round Robin algorithm and how does it convert a deadlock-free protocol to bounded bypass?", "back": "Round Robin algorithm:\n```\nInitialize FLAG[i] to down (∀i) and TURN to any process ID\n\nlock(i) := \n  FLAG[i] ← up\n  wait (TURN = i OR FLAG[TURN] = down)\n  DLF.lock(i)\n  return\n\nunlock(i) :=\n  FLAG[i] ← down\n  if FLAG[TURN] = down then TURN ← (TURN+1) mod n\n  DLF.unlock(i)\n  return\n```\n\nThis converts any deadlock-free protocol DLF into a bounded bypass protocol with bound n(n-1)."}
{"front": "How does the Round Robin algorithm ensure bounded bypass?", "back": "If FLAG[i] = up, then TURN is set to i in at most (n-1)² iterations (Lemma 2). Once TURN = i, pi enters CS in at most (n-1) iterations (Lemma 1). Total: (n-1)² + (n-1) = n(n-1) iterations, proving bounded bypass with bound n(n-1)."}
{"front": "What is a Safe Register and how does it differ from an Atomic Register?", "back": "A MRSW Safe register provides READ and WRITE such that:\n1. Every READ that doesn't overlap with a WRITE returns the value stored in the register\n2. A READ that overlaps with a WRITE returns ANY value in the register domain\n\nA MRMW Safe register acts like MRSW when WRITEs don't overlap; when WRITEs overlap, it can contain any value in the register domain.\n\nUnlike Atomic Registers, operations aren't guaranteed to look instantaneous."}
{"front": "Describe the Test&set primitive and how it can be used for MUTEX", "back": "The Test&set primitive atomically reads and sets a boolean register:\n```\nX.test&set() :=\n  tmp ← X\n  X ← 1  (atomic)\n  return tmp\n```\n\nMUTEX implementation:\n```\nInitialize X at 0\n\nlock() :=\n  wait X.test&set() = 0\n  return\n\nunlock() :=\n  X ← 0\n  return\n```\n\nThis algorithm satisfies deadlock freedom but may allow starvation."}
{"front": "Describe the Compare&swap primitive and how it can be used for MUTEX", "back": "The Compare&swap primitive atomically compares and possibly updates a register:\n```\nX.compare&swap(old, new) :=\n  if X = old then X ← new\n    return true  (atomic)\n  return false\n```\n\nMUTEX implementation:\n```\nInitialize X at 0\n\nlock() :=\n  wait X.compare&swap(0,1)=true\n  return\n\nunlock() :=\n  X ← 0\n  return\n```"}
{"front": "Describe the Fetch&add primitive and how it can be used for MUTEX", "back": "The Fetch&add primitive atomically reads and increments an integer register:\n```\nX.fetch&add(v) :=\n  tmp ← X\n  X ← X+v  (atomic)\n  return tmp\n```\n\nMUTEX implementation:\n```\nInitialize TICKET and NEXT at 0\n\nlock() :=\n  my_tick ← TICKET.fetch&add(1)\n  wait my_tick = NEXT\n  return\n\nunlock() :=\n  NEXT ← NEXT+1\n  return\n```\n\nThis implements a fair first-come-first-served queue:\n- Each process gets a unique ticket number\n- Processes wait until their ticket number equals NEXT\n- When a process exits CS, it increments NEXT, allowing the next waiting process to enter\n\nThis guarantees bounded bypass with bound n-1 (a process can be bypassed by at most n-1 others who already have smaller ticket numbers)."}
{"front": "How can we prove that the Bakery algorithm ensures mutual exclusion despite using only safe registers?", "back": "Proof of mutual exclusion for Bakery algorithm:\n\n1. Assume, by contradiction, that processes pi and pj are simultaneously in CS\n\n2. By Lemma 2 (if pi is in CS and pj is in doorway/bakery, then ⟨MY_TURN[i],i⟩ < ⟨MY_TURN[j],j⟩), applied twice:\n   - ⟨MY_TURN[i],i⟩ < ⟨MY_TURN[j],j⟩\n   - ⟨MY_TURN[j],j⟩ < ⟨MY_TURN[i],i⟩\n\n3. These inequalities create a contradiction as the lexicographic ordering is strict\n\nThe key insight is that even with non-atomic operations, the algorithm ensures a total ordering of processes through ticket numbers paired with process IDs."}
{"front": "Explain how Lamport's Bakery algorithm proves that mutual exclusion is possible without atomic operations", "back": "Lamport's Bakery algorithm proves mutual exclusion is possible without atomic operations by:\n\n1. Using only safe registers (where concurrent reads/writes may return any value)\n\n2. Employing a two-phase protocol:\n   - Doorway phase (getting a ticket): non-blocking, finite steps\n   - Waiting phase: may block but eventually succeeds\n\n3. Creating a total ordering of processes via lexicographically ordered tickets\n\n4. Using redundant checking (both FLAG and MY_TURN) to handle non-atomic operations\n\nThis demonstrated that mutual exclusion could be implemented even in systems without hardware-supported atomic operations, an important theoretical breakthrough in distributed computing."}
{"front": "How does the improved Aravind algorithm address the bounded register limitation of the Bakery algorithm?", "back": "Aravind's algorithm addresses the bounded register limitation:\n\n1. Bakery problem: MY_TURN registers grow unboundedly as processes enter CS\n\n2. Aravind's solution:\n   - Uses DATE registers with range [1,2n] instead of unbounded counters\n   - Implements a reset mechanism: when max DATE reaches 2n, resets all DATEs to initial values\n   - Uses two-phase checking with FLAG and STAGE registers to maintain correctness\n\n3. The algorithm maintains mutual exclusion while ensuring that:\n   - Registers stay within bounded range\n   - Bounded bypass is preserved (with bound 2n-2)\n   - Deadlock freedom is guaranteed\n\nThis makes the algorithm implementable with fixed-size registers in hardware."}
{"front": "Explain the concept of \"helping\" in concurrent algorithms and how it relates to liveness properties", "back": "\"Helping\" in concurrent algorithms:\n\n1. Definition: A process helps another when it performs operations that contribute to the other process's progress\n\n2. Implementation: Process A may complete part of process B's work when A detects B is blocked\n\n3. Relationship to liveness:\n   - Improves deadlock freedom: Blocked processes can make progress through helpers\n   - Enhances starvation freedom: A process repeatedly blocked by others might be helped\n   - Reduces contention: Instead of competing, processes cooperate\n\n4. Example in Round Robin: When a process completes and finds FLAG[TURN]=down, it increments TURN to help the next process\n\nHelping is a key technique for improving liveness properties beyond what's possible with purely competitive approaches."}
{"front": "Compare and contrast the three main solutions for the Readers/Writers problem (weak priority to readers, strong priority to readers, and fair solution)", "back": "Readers/Writers problem solutions comparison:\n\n1. Weak priority to readers:\n   • If a reader arrives during a read, it can proceed before waiting writers\n   • When a writer terminates, it activates the first suspended process regardless of type\n   • May cause writer starvation if readers continuously arrive\n\n2. Strong priority to readers:\n   • When a writer terminates, it activates the first reader if any, otherwise first writer\n   • Introduces dedicated W_MUTEX to manage writer queue\n   • Ensures readers are always prioritized, guaranteeing writer starvation\n\n3. Fair solution:\n   • After a write, all waiting readers are enabled\n   • During a read, new readers must wait if writers are waiting\n   • Balances throughput with fairness\n   • Prevents indefinite starvation of either type\n\nThe choice depends on whether throughput (reader priority) or fairness is more important."}
{"front": "Explain how Monitor condition variables differ from semaphores and why they provide a higher-level abstraction", "back": "Monitor condition variables vs. semaphores:\n\n1. Structural differences:\n   • Semaphores combine synchronization and data in one entity\n   • Condition variables are always associated with a monitor and its lock\n\n2. Operational differences:\n   • Semaphores: up/down affect counter directly\n   • Condition variables: wait/signal affect nothing if no processes are waiting\n\n3. Higher-level abstraction:\n   • Encapsulation: Monitors hide synchronization mechanisms\n   • Automatic locking: Monitor ensures mutual exclusion\n   • Semantic clarity: Condition variables express \"wait until condition true\"\n   • Reduced errors: Harder to forget to release a lock\n\n4. Usage pattern:\n   • Semaphores require careful protocol design\n   • Monitors allow reasoning about logical conditions\n\nThis makes monitors easier to use correctly and reason about in complex concurrent systems."}
{"front": "Explain how Peterson's algorithm for n processes uses a \"filtering\" approach to ensure mutual exclusion", "back": "Peterson's n-process algorithm filtering approach:\n\n1. Structured as n-1 filtering levels that processes must pass through\n\n2. At each level l (1 to n-1):\n   • Process sets its FLAG to l (\"I want to pass this level\")\n   • Process sets AFTER_YOU[l] to its ID (\"I'll wait if needed\")\n   • Process waits if another process has same/higher level AND has priority\n\n3. Progressive elimination:\n   • Level 1: At most n-1 processes pass\n   • Level 2: At most n-2 processes pass\n   • ...\n   • Level n-1: At most 1 process passes (enters CS)\n\n4. Competition resolution at each level:\n   • Last process to set AFTER_YOU becomes \"victim\" if conflict\n   • Other processes with FLAG≥l must have already passed or are blocked\n\nThis sequential filtering guarantees exactly one process reaches the critical section."}
{"front": "What are the practical and theoretical implications of achieving bounded bypass with O(n²) complexity vs. deadlock freedom with O(1) complexity?", "back": "Implications of bounded bypass O(n²) vs. deadlock freedom O(1):\n\nPractical implications:\n- Performance tradeoff: O(1) algorithms offer better performance, especially under high contention\n- Predictability: Bounded bypass provides guaranteed upper bounds on waiting time\n- Fairness: O(n²) bounded bypass ensures all processes eventually proceed\n- Resource usage: O(1) algorithms typically use fewer shared variables and memory\n\nTheoretical implications:\n- Complexity hierarchy: Shows fundamental tradeoffs between fairness and efficiency\n- Impossibility results: Demonstrates you can't have both O(1) complexity and bounded bypass\n- Algorithm transformation: Proves any deadlock-free algorithm can be transformed to bounded bypass (at cost of efficiency)\n- Asynchronous computing model: Highlights limitations of what's achievable in asynchronous systems\n\nCombined, these show the fundamental tension between efficiency and fairness in concurrent systems."}
{"front": "How does the tournament-based MUTEX algorithm leverage divide-and-conquer to improve performance?", "back": "Tournament-based MUTEX divide-and-conquer approach:\n\n1. Hierarchical structure:\n   • Processes arranged in a binary tournament tree\n   • n leaf nodes (processes) compete in log₂n levels\n   • Each internal node represents a 2-process MUTEX competition\n\n2. Divide-and-conquer strategy:\n   • Problem: Find 1 winner among n processes\n   • Divide: Group processes into pairs at each level\n   • Conquer: Use efficient 2-process Peterson's algorithm at each node\n   • Combine: Winners proceed to next level until root\n\n3. Performance improvement:\n   • Peterson's algorithm: O(n²) complexity\n   • Tournament approach: O(log n) complexity\n   • Each process competes in at most log₂n 2-process competitions\n\nThis leverages the efficiency of Peterson's 2-process algorithm while scaling to n processes logarithmically rather than quadratically."}
{"front": "Explain the role of the X and Y registers in Lamport's Fast MUTEX algorithm and why both are necessary", "back": "Role of X and Y registers in Lamport's Fast MUTEX:\n\n1. Y register (\"doorkeeper\"):\n   • Initially ⊥ (no one attempting CS)\n   • When set to i, indicates process i has claimed potential CS access\n   • Only one process can have Y=i at any time\n   • Reset to ⊥ on unlock, allowing next competition\n\n2. X register (\"last arrival\"):\n   • Records the last process to attempt entry\n   • Used to verify a process hasn't been \"cut in line\"\n   • If X=i when process i checks, it confirms no one came after\n\n3. Why both are necessary:\n   • Y alone: Couldn't detect if another process started competing after you\n   • X alone: Couldn't ensure exclusive access to critical section\n   • Together: Form a \"doorway\" mechanism that ensures:\n     - At most one process succeeds\n     - When contention occurs, a consistent decision is made\n\nThe combination creates a fast-path for uncontended access (5 operations) while guaranteeing correctness."}
{"front": "How does the concept of \"linearizability\" relate to the implementation of concurrent objects like locks?", "back": "Linearizability and concurrent locks:\n\n1. Linearizability definition:\n   • Each operation appears to occur instantaneously at some point between its invocation and response\n   • The result of concurrent operations is equivalent to some valid sequential execution\n\n2. Relation to locks:\n   • Atomic registers used in lock algorithms must be linearizable\n   • A lock implementation is correct if its operations (lock/unlock) are linearizable\n   • The critical section appears to execute atomically at a single point in time\n\n3. Implementation implications:\n   • Registry tracking (e.g., FLAGS in Peterson's) must reflect a consistent state\n   • Hardware primitives (test&set, compare&swap) rely on linearizability\n   • Safe registers (non-linearizable) require more complex algorithms (e.g., Bakery)\n\n4. Reasoning about correctness:\n   • Linearizability allows us to reason about interleaved executions as if sequential\n   • Mutual exclusion proves no two critical sections can overlap in the linearized history\n\nLinearizability is the theoretical foundation that makes reasoning about concurrent objects possible."}
{"front": "Describe the time and space complexity tradeoffs between different MUTEX algorithms", "back": "MUTEX algorithm time/space complexity tradeoffs:\n\n1. Peterson's algorithm (n processes):\n   • Time: O(n²) operations per lock/unlock\n   • Space: n MRSW registers + (n-1) MRMW registers\n   • Liveness: Starvation freedom\n\n2. Tournament-based algorithm:\n   • Time: O(log n) operations per lock/unlock\n   • Space: O(n) registers for tournament tree\n   • Liveness: Bounded bypass with bound log₂n\n\n3. Lamport's Fast MUTEX:\n   • Time: O(1) operations without contention, potentially unbounded with contention\n   • Space: n MRSW FLAG registers + 2 MRMW registers (X, Y)\n   • Liveness: Only deadlock freedom\n\n4. Bakery algorithm:\n   • Time: O(n) operations per lock/unlock\n   • Space: 2n registers, but MY_TURN registers are unbounded\n   • Liveness: Bounded bypass with bound n-1\n\n5. Hardware primitives (fetch&add):\n   • Time: O(1) operations per lock/unlock\n   • Space: 2 integer registers\n   • Liveness: Bounded bypass with bound n-1\n\nThe general pattern shows stronger liveness properties or weaker hardware assumptions require more complex algorithms."}
{"front": "How does the concept of \"wait-freedom\" differ from the liveness properties discussed in the course, and why is it significant?", "back": "Wait-freedom vs. course liveness properties:\n\n1. Definition of wait-freedom:\n   • Every process completes its operation in a finite number of steps\n   • Progress guaranteed regardless of other processes' speeds or failures\n   • Stronger than deadlock freedom, starvation freedom, and bounded bypass\n\n2. Key differences:\n   • Bounded bypass: Limits how many times a process can be bypassed\n   • Wait-freedom: Guarantees completion in a bounded number of *steps*\n   • Resilience: Wait-freedom works even if processes crash\n\n3. Significance:\n   • Real-time systems: Provides hard guarantees on operation completion\n   • Fault tolerance: Continues progress despite process failures\n   • Composability: Wait-free components compose into wait-free systems\n   • Theoretical importance: Represents strongest practical liveness property\n\n4. Limitations:\n   • Difficult to implement (often requires strong primitives like compare&swap)\n   • Performance overhead compared to blocking algorithms\n   • Not covered in detail in this course but represents an important direction in concurrent programming\n\nWait-freedom extends the liveness hierarchy beyond bounded bypass and provides stronger resilience guarantees."}
{"front": "Analyze the relationship between the concept of \"consensus number\" and the hardware primitives discussed in the course", "back": "Consensus number and hardware primitives:\n\n1. Consensus number definition:\n   • Maximum number of processes for which the primitive can solve consensus\n   • Consensus: All processes agree on one of their input values\n   • Higher number = more powerful primitive\n\n2. Consensus numbers of discussed primitives:\n   • Atomic read/write registers: Consensus number 1\n   • Test&set, swap, fetch&add: Consensus number 2\n   • Compare&swap: Consensus number ∞\n\n3. Relationship to MUTEX algorithms:\n   • Primitives with consensus number ≥2 can implement MUTEX for any number of processes\n   • Register-based MUTEX (Peterson's) requires complex algorithms\n   • More powerful primitives enable simpler, more efficient algorithms\n\n4. Theoretical significance:\n   • Herlihy's hierarchy: Primitives classified by consensus number\n   • Universality: Consensus number ∞ primitives can implement any concurrent object\n   • Shows fundamental limits of what's possible with certain primitives\n\nThis explains why certain primitives enable O(1) MUTEX while others require more complex solutions."}
{"front": "Explain how the concept of \"helping\" is implemented in the Round Robin algorithm and how it ensures bounded bypass", "back": "Helping in Round Robin algorithm:\n\n1. Implementation mechanism:\n   • TURN variable tracks whose turn it is to enter CS\n   • FLAG array indicates which processes want to enter\n   • When a process unlocks: `if FLAG[TURN] = down then TURN ← (TURN+1) mod n`\n\n2. Helping behavior:\n   • Process i finishing its CS checks if process TURN wants to enter\n   • If not (FLAG[TURN]=down), process i advances TURN to the next process\n   • This \"helps\" other processes by moving the turn marker forward\n   • Without this, TURN might get stuck at a process that's not competing\n\n3. Bounded bypass guarantee:\n   • If FLAG[i]=up, TURN will advance to i in at most (n-1)² iterations\n   • Once TURN=i, process i enters CS in at most n-1 more iterations\n   • Total bound: n(n-1) iterations\n\n4. Key insight:\n   • Processes actively collaborate to ensure fairness\n   • Finishing processes take responsibility for system-wide progress\n   • This cooperation transforms deadlock freedom into bounded bypass\n\nHelping enables stronger liveness guarantees without requiring more complex synchronization primitives."}
{"front": "Compare the theoretical foundations of Peterson's algorithm and Lamport's Bakery algorithm", "back": "Peterson vs. Bakery theoretical foundations:\n\n1. Computational model assumptions:\n   • Peterson: Requires atomic registers with linearizable operations\n   • Bakery: Works with weaker safe registers (non-atomic)\n\n2. Fundamental mechanisms:\n   • Peterson: Competition resolution via victim selection (AFTER_YOU)\n   • Bakery: Total ordering via timestamps (MY_TURN) and lexicographic comparison\n\n3. Filtering approach:\n   • Peterson: Sequential levels that progressively filter out processes\n   • Bakery: Single-level competition based on ticket numbers\n\n4. Communication pattern:\n   • Peterson: Each process communicates its level and reads others'\n   • Bakery: Two-phase protocol (doorway + bakery) with redundant checking\n\n5. Theoretical significance:\n   • Peterson: Optimal space complexity for atomic registers\n   • Bakery: Proved MUTEX possible without atomicity\n\nThese algorithms represent two fundamental approaches to MUTEX: hierarchical filtering vs. total ordering, with different assumptions about the underlying system."}
{"front": "How does the implementation of semaphores relate to the concept of \"meta-mutual exclusion\" and why is this important?", "back": "Semaphores and meta-mutual exclusion:\n\n1. Meta-mutual exclusion problem:\n   • Primitives that implement MUTEX must themselves be implemented using MUTEX\n   • Creates a circular dependency: How to implement the first MUTEX?\n\n2. Semaphore implementation requires MUTEX:\n   ```\n   S.down() :=              S.up() :=\n     Disable interrupts      Disable interrupts\n     wait S.t.test&set()=0   wait S.t.test&set()=0\n     S.counter--             S.counter++\n     if S.counter<0 then     if S.counter≤0 then\n       enter into S.queue      activate proc from S.queue\n     S.t←0                   S.t←0\n     Enable interrupts       Enable interrupts\n     SUSPEND                 return\n     return\n   ```\n\n3. Breaking the circularity:\n   • Hardware-level atomic primitives (test&set)\n   • Disabling interrupts (uniprocessor systems)\n   • Hardware-level MUTEX (multiprocessor systems)\n\n4. Importance:\n   • Shows fundamental need for hardware support\n   • Defines minimum hardware capabilities needed\n   • Explains why some primitives are implemented in hardware\n   • Establishes a hierarchy of synchronization mechanisms\n\nThis demonstrates that software-only MUTEX is impossible; some hardware support is always needed at the foundation."}
{"front": "Explain how starvation can still occur in deadlock-free MUTEX algorithms", "back": "Starvation in deadlock-free MUTEX algorithms:\n\n1. Mechanism of starvation:\n   • Adversarial scheduling: A scheduler consistently favors certain processes\n   • Always overtaken: Process P repeatedly attempts to enter CS but always finds other processes ahead\n   • Reset conditions: Process P makes progress but gets reset by others' actions\n\n2. Concrete example (fast MUTEX):\n   ```\n   Process P1: sets FLAG[1]=up, X=1, finds Y=⊥, sets Y=1, finds X=1, enters CS\n   Process P2: sets FLAG[2]=up, X=2, finds Y=⊥, sets Y=2, finds X=2, enters CS\n   Process P3: sets FLAG[3]=up, X=3, finds Y≠⊥, sets FLAG[3]=down, waits for Y=⊥\n   ```\n   This can repeat indefinitely, with P1 and P2 alternating while P3 starves\n\n3. Deadlock freedom only guarantees:\n   • System-wide progress (some process enters CS)\n   • Not individual process progress\n\n4. Formal characterization:\n   • Fair scheduling is not guaranteed in asynchronous systems\n   • Bounded bypass requires explicit mechanisms to track and limit bypassing\n\nThis shows why stronger fairness properties like starvation freedom and bounded bypass require more complex algorithms."}
{"front": "Explain how Lamport's Fast MUTEX algorithm balances efficiency for the uncontended case with correctness for the contended case", "back": "Lamport's Fast MUTEX efficiency/correctness balance:\n\n1. Uncontended fast path (efficiency):\n   ```\n   FLAG[i] ← up\n   X ← i\n   if Y = ⊥ then Y ← i\n   if X = i then return  // Fast path success\n   ```\n   • Only 5 register accesses in best case\n   • No loops or waiting for other processes\n   • O(1) time complexity when no contention\n\n2. Contended slow path (correctness):\n   ```\n   FLAG[i] ← down\n   ∀j.wait FLAG[j] = down  // Wait for competing processes\n   if Y = i then return     // Still my turn\n   else wait Y = ⊥          // Wait for next opportunity\n   goto *                   // Try again\n   ```\n   • Complex waiting mechanism ensures safety\n   • Guarantees deadlock freedom even under contention\n   • May require multiple attempts but eventually succeeds\n\n3. Key insight:\n   • Fast path optimized for common case (no contention)\n   • Slow path ensures correctness in worst case\n   • Uses single protocol for both scenarios\n\nThis approach influenced many practical lock implementations that optimize for uncontended access while maintaining correctness."}
{"front": "What is the relationship between the number of processes (n) and the bound function f(n) in bounded bypass algorithms?", "back": "Relationship between n and f(n) in bounded bypass:\n\n1. Definition: A MUTEX algorithm satisfies bounded bypass if there exists f:N→N such that every process enters CS after at most f(n) other CS entries\n\n2. Lower bounds:\n   • Any bounded bypass algorithm requires at least f(n) ≥ n-1\n   • Intuition: If all n processes compete, one might wait for all others\n\n3. Achievable bounds in different algorithms:\n   • Peterson (2 processes): f(n) = 1\n   • Tournament-based: f(n) = ⌈log₂ n⌉\n   • Bakery algorithm: f(n) = n-1\n   • Round Robin transformation: f(n) = n(n-1)\n   • Improved Aravind: f(n) = n-1\n\n4. Tradeoffs:\n   • Tighter bounds (smaller f(n)) generally require:\n     - More complex algorithms\n     - More powerful primitives\n     - More shared variables\n\n5. Asymptotic perspective:\n   • Linear bound O(n) is achievable with simple algorithms\n   • Constant bound O(1) is impossible with finite registers\n\nThis shows fundamental limits on fairness guarantees achievable with different resources."}
{"front": "Explain the relationship between Safe Registers, Regular Registers, and Atomic Registers", "back": "Safe vs. Regular vs. Atomic Registers:\n\n1. Safe Register properties:\n   • Non-overlapping read/write: Returns correct value\n   • Overlapping read/write: May return any value in register domain\n   • Weakest useful register type\n\n2. Regular Register properties:\n   • Non-overlapping read/write: Returns correct value\n   • Overlapping read/write: Returns either old or new value\n   • Stronger than Safe but weaker than Atomic\n\n3. Atomic Register properties:\n   • Linearizable: Operations appear to occur instantaneously\n   • Always returns a value consistent with sequential execution\n   • Strongest and most intuitive register type\n\n4. Implementation hierarchy:\n   • Safe registers can be implemented directly in hardware\n   • Regular registers can be built from Safe registers\n   • Atomic registers can be built from Regular registers\n   • Each transformation adds complexity\n\n5. Algorithm requirements:\n   • Bakery algorithm works with Safe registers\n   • Peterson's algorithm requires Atomic registers\n   • Most hardware primitives provide Atomic semantics\n\nThis hierarchy shows the progression of register types and their implications for MUTEX algorithms."}
{"front": "Compare and contrast the Producer-Consumer problem with the Readers-Writers problem", "back": "Producer-Consumer vs. Readers-Writers:\n\n1. Core problem structure:\n   • Producer-Consumer: Two roles interacting through shared buffer\n   • Readers-Writers: Two roles accessing shared resource\n\n2. Access pattern:\n   • Producer-Consumer: Sequential (producers add, consumers remove)\n   • Readers-Writers: Concurrent for readers, exclusive for writers\n\n3. Synchronization requirements:\n   • Producer-Consumer: Buffer bounds (full/empty) and mutual exclusion\n   • Readers-Writers: Role-based policies and mutual exclusion\n\n4. Key constraints:\n   • Producer-Consumer: Consumed items must be produced first\n   • Readers-Writers: Multiple readers OR one writer\n\n5. Fairness considerations:\n   • Producer-Consumer: Balance production/consumption rates\n   • Readers-Writers: Priority policies (reader vs. writer preference)\n\n6. Solution approaches:\n   • Producer-Consumer: Semaphores for buffer slots\n   • Readers-Writers: Counters and multiple semaphores\n\nBoth problems represent fundamental concurrent access patterns but with different sharing semantics and optimization goals."}
{"front": "Explain how the Dining Philosophers problem illustrates the challenges of deadlock avoidance in resource allocation", "back": "Dining Philosophers and deadlock avoidance:\n\n1. Core deadlock pattern:\n   • Circular wait: Each philosopher holds one resource, waits for another\n   • No preemption: Resources cannot be forcibly released\n   • Mutual exclusion: Each chopstick used by only one philosopher\n   • Hold and wait: Philosophers don't release held resources while waiting\n\n2. Deadlock avoidance strategies:\n   • Breaking symmetry: Different acquisition order for different philosophers\n   • Resource hierarchy: Number chopsticks, acquire in ascending order\n   • Limited concurrency: Allow at most n-1 philosophers to compete\n   • All-or-nothing acquisition: Acquire both chopsticks atomically\n\n3. Relationship to general resource allocation:\n   • Represents shared resources with multiple users\n   • Models partial allocation and incremental acquisition\n   • Illustrates cascading dependencies and circular wait conditions\n   • Shows importance of global resource management strategies\n\n4. Theoretical significance:\n   • Proves impossibility of certain distributed coordination problems\n   • Demonstrates need for system-level deadlock management\n   • Shows tradeoffs between fairness, concurrency, and complexity\n\nThis problem serves as a canonical example of deadlock conditions and solutions in concurrent systems."}
{"front": "What is the Bakery algorithm and what problem does it solve?", "back": "The Bakery algorithm (Lamport 1974) enforces MUTEX using only safe registers (without atomicity). Key idea:\n- Every process gets a ticket number\n- Without atomicity, tickets may not be unique\n- Tickets are paired with process IDs to make them unique\n- The smallest ticket (lexicographically) grants access to the CS\n\nThe algorithm works by having processes first signal they want a ticket (doorway phase), then take a number, then check if they have the lowest number (bakery phase)."}
{"front": "Describe the Bakery algorithm implementation", "back": "```\nInitialize FLAG[i] to down and MY_TURN[i] to 0, for all i\n\nlock(i) :=\n  FLAG[i] ← up                              # doorway\n  MY_TURN[i] ← max{MY_TURN[1],…,MY_TURN[n]}+1 \n  FLAG[i] ← down                            # \n  forall j ≠ i                              # bakery\n    wait FLAG[j] = down                     # (including CS)\n    wait (MY_TURN[j] = 0 OR                #\n         ⟨MY_TURN[i],i⟩ < ⟨MY_TURN[j],j⟩)  #\n\nunlock(i) :=\n  MY_TURN[i] ← 0\n```"}
{"front": "What are the key properties of the Bakery algorithm?", "back": "The Bakery algorithm:\n- Satisfies MUTEX: By comparing ticket numbers, at most one process can enter the CS\n- Ensures Deadlock freedom: The lexicographic ordering of tickets breaks ties\n- Provides Bounded bypass with bound n-1: A process can be bypassed at most n-1 times\n- Uses only safe registers (doesn't require atomicity)\n- Uses potentially unbounded counters (every invocation of lock potentially increases the counter by 1)"}
{"front": "What is Aravind's algorithm (2011) and what improvement does it make to Lamport's Bakery algorithm?", "back": "Aravind's algorithm (2011) addresses the key limitation of Lamport's Bakery algorithm: the potentially unbounded registers. \n\nAravind uses bounded registers:\n- For all processes: a FLAG and a STAGE (both binary MRSW), and a DATE (a MRMW register ranging from 1 to 2n)\n- Resets DATE registers after n critical sections\n\nIt satisfies bounded bypass with bound 2n-2, while maintaining the MUTEX property."}
{"front": "Describe the Producer/Consumer problem and how semaphores can solve it", "back": "The Producer/Consumer problem involves a shared FIFO buffer where producers add items and consumers remove them.\n\nSolution with semaphores:\n- BUF[0,…,k-1]: Generic registers for the buffer\n- IN/OUT: Variables pointing to locations in BUF, initialized at 0\n- FREE/BUSY: Two semaphores counting the number of free/busy cells, initialized at k and 0\n\n```\nB.produce(v) :=           B.consume() :=\n  FREE.down()               BUSY.down()\n  BUF[IN] ← v               tmp ← BUF[OUT]\n  IN ← (IN+1) mod k         OUT ← (OUT+1) mod k\n  BUSY.up()                 FREE.up()\n  return                    return tmp\n```"}
{"front": "What is a Semaphore and what are its key operations?", "back": "A Semaphore is a shared counter S accessed via primitives up and down such that:\n1. It is initialized at s0 ≥ 0\n2. It is always ≥ 0\n3. up atomically increases S\n4. down atomically decreases S if it's not 0; otherwise, the invoking process is blocked\n\nInvariant: S = s0 + #(S.up) - #(S.down)\n\nMain use: Prevent busy waiting by suspending processes that cannot perform down."}
{"front": "Describe the difference between strong and weak semaphores, and between binary and counting semaphores", "back": "- Strong semaphores use a FIFO policy for blocking/unblocking processes, while weak semaphores don't guarantee any order\n- Binary semaphores can only have values 0 or 1 (up operations are also blocking if the value is already 1), while counting semaphores can have any non-negative integer value"}
{"front": "How are semaphores typically implemented?", "back": "Semaphores are typically implemented with:\n1. A counter (that can be negative): If counter ≥ 0, this is the semaphore value; if counter < 0, this indicates how many processes are suspended\n2. A data structure (typically a queue) to store suspended processes\n\nOperations are executed in mutual exclusion:\n```\nS.down() :=                S.up() :=\n  S.counter--                 S.counter++\n  if S.counter < 0 then       if S.counter ≤ 0 then\n    enter into S.queue          activate a proc from S.queue\n    SUSPEND                     return\n  return\n```"}
{"front": "What is the Readers/Writers problem?", "back": "The Readers/Writers problem involves managing access to a shared resource:\n- Several processes want to access a file\n- Readers may simultaneously access the file (multiple readers allowed)\n- At most one writer at a time (exclusive access)\n- Reads and writes are mutually exclusive\n\nThis generalizes the MUTEX problem (MUTEX = Readers/Writers with only writers)."}
{"front": "Describe the solution to the Readers/Writers problem with weak priority to readers", "back": "Weak priority to readers: If a reader arrives during a read, it can proceed before waiting writers\n\n```\nGLOB_MUTEX and R_MUTEX semaphores init. at 1\nR a shared register init. at 0\n\nbegin_read() :=          end_read() :=\n  R_MUTEX.down()           R_MUTEX.down()\n  R++                      R--\n  if R = 1 then            if R = 0 then\n    GLOB_MUTEX.down()        GLOB_MUTEX.up()\n  R_MUTEX.up()            R_MUTEX.up()\n  return                   return\n\nbegin_write() :=         end_write() :=\n  GLOB_MUTEX.down()        GLOB_MUTEX.up()\n  return                   return\n```"}
{"front": "What is a Monitor in concurrent programming?", "back": "A Monitor is a high-level concurrent object that:\n- Guarantees that at most one operation invocation at a time is active inside it\n- Provides internal inter-process synchronization through conditions\n- Allows operations to wait on conditions and signal them\n- Simplifies concurrent programming compared to low-level primitives like semaphores\n\nConditions provide wait and signal operations with either Hoare semantics (signaler suspends) or Mesa semantics (signaler continues)."}
{"front": "How can Monitors be implemented using semaphores?", "back": "Monitors can be implemented using semaphores:\n- A semaphore MUTEX init at 1 (for mutual exclusion)\n- For each condition C: a semaphore SEM_C init at 0 and an integer N_C init at 0\n- A semaphore PRIO init at 0 and an integer N_PR init at 0\n\nOperations:\n1. Monitor operations start with MUTEX.down() and end with conditional PRIO or MUTEX release\n2. C.wait() suspends the process, releases the monitor, and waits on SEM_C\n3. C.signal() activates a suspended process on condition C if any exist"}
{"front": "What is the Dining Philosophers problem?", "back": "The Dining Philosophers problem (Dijkstra, 1965):\n- N philosophers seated around a circular table\n- One chopstick between each pair of philosophers\n- A philosopher must pick up both nearest chopsticks to eat\n- A philosopher must pick up one chopstick at a time\n\nThe challenge is to devise a deadlock-free algorithm for allocating limited resources (chopsticks) among several processes (philosophers)."}
{"front": "Why does the naive solution to the Dining Philosophers problem cause deadlock?", "back": "The naive solution:\n```\nsemaphore chopstick[5] initialized to 1\nPhilosopher(i) :=\n  while(1) do\n    chopstick[i].down()\n    chopstick[(i+1)%N].down()\n    // eat\n    chopstick[(i+1)%N].up()\n    chopstick[i].up()\n```\n\nThis can deadlock if all philosophers simultaneously grab their right chopstick and then try to grab their left chopstick - each is holding one resource and waiting for another that will never be released."}
{"front": "List at least three ways to solve the Dining Philosophers problem", "back": "Solutions to the Dining Philosophers problem:\n\n1. Break symmetry by chopstick order: All philosophers grab left first, except one grabs right first\n\n2. Break symmetry by philosopher behavior: Odd philosophers pick left-then-right, even philosophers pick right-then-left\n\n3. Limit concurrency: Allow at most N-1 philosophers at the table\n\n4. Resource allocation with atomicity: A philosopher can pick up chopsticks only if both are free (using monitors)"}
{"front": "Explain how to use a monitor to solve the Dining Philosophers problem", "back": "Monitor solution:\n```\nmonitor DP\n  status state[N] all initialized at thinking;\n  condition self[N];\n  \n  Pickup(i) :=\n    state[i] = hungry;\n    test(i);\n    if (state[i] != eating) then self[i].wait;\n  \n  Putdown(i) :=\n    state[i] = thinking;\n    test((i+1)%N);\n    test((i-1)%N);\n  \n  test(i) :=\n    if (state[(i+1)%N] != eating && state[(i-1)%N] != eating\n      && state[i] == hungry)\n    then state[i] = eating;\n      self[i].signal();\n```\n\nPhilosophers only eat if both neighbors aren't eating, avoiding deadlock."}
{"front": "List the asymptotic complexities of different MUTEX algorithms for n processes", "back": "MUTEX algorithm complexities for n processes:\n\n- Peterson's algorithm: O(n²) with starvation freedom\n- Tournament-based algorithm: O(log n) with bounded bypass (bound ⌈log₂ n⌉)\n- Lamport's Fast MUTEX: O(1) with deadlock freedom\n- For 2 processes: Peterson's algorithm achieves O(1) with bounded bypass (bound 1)"}
{"front": "What is the main idea behind the improved version of Aravind's algorithm?", "back": "The improved version of Aravind's algorithm modifies the UNLOCK procedure:\n```\nunlock(i) :=\n  ∀j≠i.if DATE[j] > DATE[i] then DATE[j] ← DATE[j]-1\n  DATE[i] ← n\n  STAGE[i] ← 0\n  FLAG[i] ← down\n```\n\nThis adjustment decreases the ticket numbers of processes that arrived later, avoiding the reset mechanism of the original algorithm and improving the bounded bypass property from 2n-2 to n-1."}
{"front": "How can a MUTEX algorithm be proven to satisfy the mutual exclusion property?", "back": "To prove a MUTEX algorithm satisfies mutual exclusion:\n\n1. Assume, by contradiction, that two processes pi and pj are simultaneously in their critical sections\n\n2. Analyze the execution paths that led each process to enter its critical section\n\n3. Identify the orderings of key operations (like register reads/writes) that must have occurred\n\n4. Show that these orderings create a contradiction (either a cycle in the happens-before relation or a violation of the algorithm's invariants)\n\nThe proof often involves considering all possible interleavings of operations."}
{"front": "What's the difference between SRSW, SRMW, MRSW, and MRMW registers?", "back": "- SRSW (Single-Reader/Single-Writer): Only one specific process can read and only one specific process can write\n\n- SRMW (Single-Reader/Multiple-Writer): Only one specific process can read, but multiple processes can write\n\n- MRSW (Multiple-Reader/Single-Writer): Multiple processes can read, but only one specific process can write\n\n- MRMW (Multiple-Reader/Multiple-Writer): Multiple processes can both read and write"}
{"front": "Why is both safety and liveness needed for concurrent algorithms?", "back": "Both safety and liveness are needed to avoid trivial solutions:\n\n- Safety without liveness: We could simply forbid any activity in the system (e.g., never grant access to the critical section). This ensures nothing bad happens but makes the algorithm useless.\n\n- Liveness without safety: We could allow anything to happen (e.g., let all processes enter their critical sections simultaneously). This ensures progress but allows incorrect behavior.\n\nSafety is necessary for correctness, liveness for meaningfulness."}
{"front": "Describe the Producer-Consumer problem and a key challenge in implementing it", "back": "The Producer-Consumer problem involves:\n- Producers that generate data\n- Consumers that process data\n- A shared buffer between them\n\nConstraints:\n- Only produced data can be consumed\n- Every datum can be consumed at most once\n\nKey challenge: Synchronizing access to the shared buffer to prevent:\n- Buffer overflow (producers adding to a full buffer)\n- Buffer underflow (consumers taking from an empty buffer)\n- Race conditions when multiple producers or consumers access the buffer simultaneously"}
{"front": "What is a Rendezvous and how can it be implemented with a monitor?", "back": "A Rendezvous is a synchronization mechanism where multiple processes meet at control points (forming a barrier) before any can proceed.\n\nMonitor implementation:\n```\nmonitor RNDV :=\n  cnt ∈ {0,…,m} init at 0\n  condition B\n  \n  operation barrier() :=\n    cnt++\n    if cnt < m then B.wait()\n    else cnt ← 0\n      B.signal()\n    return\n```\n\nThis ensures all m processes reach the barrier before any continues."}
{"front": "How does the complexity of MUTEX protocols vary with the computational model?", "back": "MUTEX protocol complexity varies by computational model:\n\n1. With atomic R/W registers:\n   - For 2 processes: O(1) with bounded bypass\n   - For n processes: O(n²), O(log n), or O(1) depending on liveness property\n\n2. With specialized HW primitives (test&set, swap, etc.):\n   - O(1) for n processes, possibly with bounded bypass\n\n3. With safe registers (non-atomic):\n   - Still possible to achieve MUTEX with algorithms like Bakery\n   - But may require unbounded registers\n\nMore powerful primitives generally allow simpler and more efficient solutions."}
{"front": "What is busy waiting and how do semaphores help avoid it?", "back": "Busy waiting is when a process continuously checks a condition in a loop, consuming CPU cycles while waiting for the condition to become true.\n\nSemaphores help avoid busy waiting by:\n- Suspending processes that cannot proceed (when down is called on a 0-valued semaphore)\n- Storing suspended processes in a queue\n- Reactivating them only when appropriate (when up is called)\n\nThis allows the CPU to work on other tasks instead of burning cycles in a wait loop."}
{"front": "Compare Peterson's algorithm with Lamport's Fast MUTEX algorithm", "back": "Peterson's algorithm vs. Lamport's Fast MUTEX:\n\nPeterson's algorithm (for n processes):\n- O(n²) complexity\n- Guarantees starvation freedom\n- Requires (n-1)(n+2) accesses for locking\n- Uses n flag registers and n-1 \"last\" registers\n\nLamport's Fast MUTEX:\n- O(1) complexity\n- Only guarantees deadlock freedom (not starvation freedom)\n- Requires just 5 accesses to registers without contention\n- Uses n flag registers, one X register, and one Y register\n\nLamport's algorithm is more efficient but provides weaker liveness guarantees."}
{"front": "What are the key differences between Java synchronized methods/blocks and semaphores?", "back": "Java synchronized vs. semaphores:\n\n- synchronized:\n  • Built into the language\n  • Ensures mutual exclusion on object monitors\n  • Automatically acquired/released on method/block entry/exit\n  • Cannot be transferred between threads\n  • Always binary (one owner at a time)\n\n- Semaphores:\n  • Explicit class in java.util.concurrent\n  • Can count resources beyond binary cases\n  • Explicitly acquired/released with acquire()/release()\n  • Permits can be acquired by one thread and released by another\n  • Can implement more complex synchronization patterns"}
{"front": "Explain how condition variables work in monitors", "back": "Condition variables in monitors:\n\n- Provide wait() and signal() operations\n- wait(): The calling process:\n  • Suspends execution\n  • Enters the condition's queue\n  • Releases mutual exclusion on the monitor\n\n- signal(): If no process is in the queue, nothing happens. Otherwise:\n  • Hoare semantics: Signaler suspends, signaled process runs with priority\n  • Mesa semantics: Signaler continues, signaled process gets priority later\n\nCondition variables allow processes to wait for specific conditions while releasing the monitor lock."}
{"front": "What is the difference between deadlock freedom and starvation freedom?", "back": "Deadlock freedom vs. starvation freedom:\n\n- Deadlock freedom: If at least one process invokes lock, then at least one process (not necessarily the same one) will eventually enter the critical section\n  • System-wide progress is guaranteed\n  • Individual processes might still wait forever\n\n- Starvation freedom: Every process that invokes lock will eventually enter its critical section\n  • Individual process progress is guaranteed\n  • Stronger property that implies deadlock freedom\n\nAn algorithm can be deadlock-free but still allow some processes to starve indefinitely."}
